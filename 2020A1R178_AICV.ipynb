{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q1: MovieLens 1M Dataset GroupLens Research provides a number of collections of movie ratings data\n",
    "    collected from users of MovieLens in the late 1990s and early 2000s. The data provide movie ratings, \n",
    "    movie metadata (genres and year), and demographic data about the users (age, zip code, gender identification,\n",
    "    and occupation). Such data is often of interest in the development of recommendation systems based on machine learning\n",
    "    algorithms. While we do not explore machine learning techniques in detail in this book, I will show you how to\n",
    "    slice and dice datasets like these into the exact form you need. The MovieLens 1M dataset contains 1 million \n",
    "    ratings collected from 6,000 users on 4,000 movies. Itâ€™s spread across three tables: ratings, user information,\n",
    "    and movie information. After extracting the data from the ZIP file, we can load each table into a pandas DataFrame\n",
    "    object using pandas.read_table and perform the following task.\n",
    "    \n",
    "1.    Perform null values identification in the given dataset.\n",
    "\n",
    "2.    Identify types of attributes in the dataset.\n",
    "\n",
    "3.    Plot Box plot and violin plot. (also state the inference of each attribute and also find the outlier in the attribute)\n",
    "\n",
    "4.    Histogram and identification of overlapping.(also state the inference for each attribute.)\n",
    "\n",
    "5.    Draw different types of scatter plot.(using seaborn library) \n",
    "\n",
    "6.    Univariate and multivariate analysis.'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load ratings, users and movies data into separate pandas DataFrame objects\n",
    "ratings = pd.read_table('ratings.dat', sep='::', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\n",
    "users = pd.read_table('users.dat', sep='::', header=None, names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'], engine='python')\n",
    "movies = pd.read_table('movies.dat', sep='::', header=None, names=['MovieID', 'Title', 'Genres'], engine='python')\n",
    "\n",
    "# Identify null values in each DataFrame\n",
    "print(ratings.isnull().sum())\n",
    "print(users.isnull().sum())\n",
    "print(movies.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "'''Types of Attributes:\n",
    "The MovieLens 1M dataset contains the following types of attributes:\n",
    "\n",
    "UserID: integer\n",
    "MovieID: integer\n",
    "Rating: integer\n",
    "Timestamp: integer\n",
    "Gender: categorical (M or F)\n",
    "Age: integer\n",
    "Occupation: categorical (0-20)\n",
    "Zip-code: string\n",
    "Title: string\n",
    "Genres: categorical (pipe-separated list of genres\n",
    "'''\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Create box plot for rating across gender categories\n",
    "sns.boxplot(x='Gender', y='Rating', data=pd.merge(ratings, users))\n",
    "\n",
    "# Create violin plot for rating across age categories\n",
    "sns.violinplot(x='Age', y='Rating', data=pd.merge(ratings, users))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create histograms for age and rating\n",
    "users['Age'].hist(bins=20)\n",
    "ratings['Rating'].hist(bins=5)\n",
    "\n",
    "# Create overlapping histograms for rating across gender categories\n",
    "ratings[ratings['Gender']=='M']['Rating'].hist(bins=5, alpha=0.5)\n",
    "ratings[ratings['Gender']=='F']['Rating'].hist(bins=5, alpha=0.5)\n",
    "plt.legend(['Male', 'Female'])\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load ratings data\n",
    "ratings = pd.read_table('ratings.dat', sep='::', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "\n",
    "# Draw a scatter plot of Rating vs Timestamp\n",
    "sns.scatterplot(x='Timestamp', y='Rating', data=ratings)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load ratings data\n",
    "ratings = pd.read_table('ratings.dat', sep='::', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "\n",
    "# Print basic statistics of Rating\n",
    "print(ratings['Rating'].describe())\n",
    "\n",
    "# Draw a histogram of Rating\n",
    "sns.histplot(x='Rating', data=ratings, bins=10)\n",
    "\n",
    "# Draw a box plot of Rating\n",
    "sns.boxplot(x='Rating', data=ratings)\n",
    "\n",
    "# Draw a scatter plot of Rating vs Timestamp\n",
    "sns.scatterplot(x='Timestamp', y='Rating', data=ratings)\n",
    "\n",
    "# Compute correlation between Rating and Timestamp\n",
    "print(ratings['Rating'].corr(ratings['Timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q2: Diabetics datasets :                                                                                                         (5 marks)\n",
    "\n",
    " Data Exploration: This includes inspecting the data, visualizing the data, and cleaning the data. Some of the steps used are as follows:\n",
    "\n",
    "1. Viewing the data statistics.\n",
    "\n",
    "2. Finding out the dimensions of the dataset, the variable names, the data types, etc.\n",
    "\n",
    "3. Checking for null values.\n",
    "\n",
    "4. Inspecting the target variable using pie plot and count plot.\n",
    "\n",
    "5. Finding out the correlation among different features using heatmap and the bivariate relation between each pair of features using pair plot.\n",
    "\n",
    "Model Training: 5 Classification Algorithms have been used to find out the best one. These are Logistic Regression, Support Vector Machine, Random Forest, K-Nearest Neighbours, and Naive Bayes.\n",
    "\n",
    "In each of the algorithms, the steps followed are as follows:\n",
    "\n",
    "1. Importing the library for the algorithm.\n",
    "\n",
    "2. Creating an instance of the Classifier (with default values of parameters or by specifying certain values in certain cases).\n",
    "\n",
    "3. Training the model on the train set.\n",
    "\n",
    "4. Prediction on the test set using the trained model.\n",
    "\n",
    "5. Calculating the accuracy of the prediction.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "df.describe()\n",
    "\n",
    "print(df.shape) # dimensions of the dataset\n",
    "print(df.columns) # variable names\n",
    "print(df.info()) # data types\n",
    "\n",
    "print(df.isnull().sum()) # number of null values in each variable\n",
    "\n",
    "print(df['Outcome'].value_counts()) # distribution of the target variable\n",
    "plt.pie(df['Outcome'].value_counts(), labels=['Non-diabetic', 'Diabetic'], autopct='%1.1f%%') # pie plot\n",
    "sns.countplot(x='Outcome', data=df) # count plot\n",
    "\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "\n",
    "sns.pairplot(df, hue='Outcome')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
